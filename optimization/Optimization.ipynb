{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Optimization of compute-bound Python code \n",
    "\n",
    "## Layout:\n",
    "\n",
    "* Foreword about optimization and profiling:\n",
    "    - No optimisation without profiling\n",
    "    - No benchmarking without tests\n",
    "* Presentation of the example:\n",
    "    - Square crystal: demonstration\n",
    "    - Relaxed circular crystal: exercise\n",
    "* `Python` version:\n",
    "    - code with loops √† la `FORTRAN`\n",
    "    - Bottleneck search\n",
    "* `Numpy` vectorized version:\n",
    "    - Limits of vectorization: cache sizes\n",
    "* A word on threading and multi-processing\n",
    "[...]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "* `Numexpr` compiler for mathematical formula\n",
    "    - Single and multi-threaded evaluation\n",
    "    - Limits of `numexpr`\n",
    "* `Numba`: just in time compilation of numerical code\n",
    "    - Decoration of function\n",
    "    - Type annotation\n",
    "    - Limits of `numba`\n",
    "* `Cython`: ahead of time compilation\n",
    "    - `Cython` usage within `Jupyter`\n",
    "    - Annotated compilation \n",
    "    - Single threaded performances\n",
    "    - Parallelization with OpenMP\n",
    "    - Mixing extensions with Python threads\n",
    "* Conclusions:\n",
    "    - Only addresses CPU-bound issues, not I/O issues\n",
    "    - Limits of parallelization: [Amdahl's law](https://en.wikipedia.org/wiki/Amdahl%27s_law)\n",
    "    - If your problem is still compute-bound, then move to GPU"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Definitions:\n",
    "* In computer science, software **optimization** is the process of modifying a software system to make some aspect of it work more efficiently or use fewer resources.[[Wikipedia](https://en.wikipedia.org/wiki/Program_optimization)]\n",
    "* In software engineering, software **profiling** is a form of dynamic program analysis that measures, for example, the space (memory) or time complexity of a program, the usage of particular instructions, or the frequency and duration of function calls. Most commonly, profiling information serves to aid program optimization, and more specifically, performance engineering. [[Wikipedia](https://en.wikipedia.org/wiki/Profiling_%28computer_programming%29)]\n",
    "* Regression **testing** is re-running functional and non-functional tests to ensure that previously developed and tested software still performs after a change. If not, that would be called a regression. [[Wikipedia](https://en.wikipedia.org/wiki/Regression_testing)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Methodology:\n",
    "\n",
    "1. **Make your algorithm work**, regardless how you implement it.\n",
    "2. Make it right and ensure it is right before writing **non-regression tests**.\n",
    "3. **Benchmark** it. \n",
    "4. If it fast enough, goto 9.\n",
    "5. **Profile** it to see where most of the time is spent.\n",
    "6. **Optimize** the code where most time is spent. \n",
    "7. **Check** non-regression tests are still passing:\n",
    "   * Fast algorithms giving wrong answers are useless!\n",
    "8. **Loop** to 3.\n",
    "9. Your work is **done** and you deserve a üç∫ !\n",
    "\n",
    "**Premature optimization is the root of all evil (or at least most of it) in programming.** *Donald Knuth*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Profiling in Python\n",
    "\n",
    "The standard library of *Python* contains the `cProfile` module which collects information about the running code. It is a *C* version of the `profile` module.\n",
    "\n",
    "Profile results can be analyzed with the `pstats` module or exernal programs like [**RunSnakeRun**](http://www.vrplumber.com/programming/runsnakerun/), [**SnakeViz**](https://jiffyclub.github.io/snakeviz/) or [**kcachegrind**](https://kcachegrind.github.io/) (using [pyprof2calltree](https://pypi.org/project/pyprof2calltree/) converter). \n",
    "\n",
    "*Profiling* induces slow-down, it should be distinguished from *benchmarking* which measures the actual performances.\n",
    "\n",
    "Here is the link to the official Python documentation: https://docs.python.org/3/library/profile.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "import math, cProfile\n",
    "\n",
    "prf = cProfile.Profile()\n",
    "prf.enable() # Start of the profiled section:\n",
    "size = 1000000\n",
    "distance = 1\n",
    "tth = []\n",
    "for i in range(size):\n",
    "    x_i = size//1000/1000\n",
    "    y_i = size%1000/1000\n",
    "    tth.append(math.atan2(math.sqrt(x_i**2 + y_i**2), distance))\n",
    "\n",
    "prf.disable() #End of section:\n",
    "\n",
    "prf.dump_stats(\"profile.log\"); prf.print_stats(sort=1) # Save / display some results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Example of visualization of the profiling with **runSnakeRun** or **SnakeViz**. Equivalent visualization is available from the other tools.\n",
    "\n",
    "This is the typical way of using the Python profiler. Another way to use it is to invoke it when starting the process:\n",
    "\n",
    "`python -m cProfile -o profile.log myscript.py`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "#!snakeviz profile.log"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# Jupyter magic functions for profiling\n",
    "\n",
    "Line magics:\n",
    "\n",
    "* `%time`: measure the time to run one statement/function call, once\n",
    "* `%timeit`: measure in benchmarking mode (many repetitions, garbage collector disabled)\n",
    "* `%prun`: run command within the profiler\n",
    "* `%lprun`: run with the line-profiler active\n",
    "* `%memit`: check for memory allocations\n",
    "* `%mprun`: run with memory profile, line per line\n",
    "\n",
    "All those functions can be used with `%%` to apply to the full cell instead of a single command.\n",
    "    \n",
    "Mind to ask for their help ... sometimes they have multiple options `%timeit?`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "%timeit?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "# Description of the system:\n",
    "import os\n",
    "import cpuinfo\n",
    "\n",
    "if hasattr(os, 'sched_getaffinity'):  # Some Unix only\n",
    "    # Get the number of cores the Python process has access to\n",
    "    # This provides the number of cores requested in SLURM\n",
    "    n_cpu = len(os.sched_getaffinity(0))\n",
    "else:\n",
    "    n_cpu = os.cpu_count()\n",
    "n_total_cpu = os.cpu_count()\n",
    "\n",
    "print(f\"We can use {n_cpu} out of the {n_total_cpu} cores of the computer\")\n",
    "# Limit the number of cores we use to at most 4\n",
    "n_cpu = min(4, n_cpu); print(f\"We are using only {n_cpu} cores\")\n",
    "\n",
    "for key, val in cpuinfo.get_cpu_info().items():\n",
    "    if \"cache_size\" in key:\n",
    "        print(key, val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Two-dimensional Laue function example\n",
    "\n",
    "All this training is based on the same example: 2D diffraction from a finite size crystallite given by Laue function:\n",
    "\n",
    "$$ I(H,K) = \\left | \\sum_{n=0}^{N-1} \\sum_{m=0}^{N-1} \\exp \\left [ 2 \\pi i \\left ( H n + K m \\right ) \\right ] \\right| ^2 $$\n",
    "\n",
    "This equation describes the scattering from a square crystal:\n",
    "- **N** is the number of unit cells of the crystal in both directions\n",
    "- **n** and **m** are the indices of the unit-cell in each direction (**real space** coordinates),\n",
    "- **H** and **K** are the continuous Miller indices (**reciprocal space** coordinates).\n",
    "\n",
    "This example is derived from: https://journals.iucr.org/j/issues/2019/04/00/gj5229/gj5229.pdf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "$$ I(H,K) = \\left | \\sum_{n=0}^{N-1} \\sum_{m=0}^{N-1} \\exp \\left [ 2 \\pi i \\left ( H n + K m \\right ) \\right ] \\right| ^2 $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cmath\n",
    "\n",
    "def laue(N, H, K):\n",
    "    \"\"\"Laue formulae for a square crystal with N¬≤ unit cells given H, K coordinate\"\"\"\n",
    "    tmp = 0.0\n",
    "    for n in range(N):  # loop and sum over unit-cells\n",
    "        for m in range(N):\n",
    "            tmp += cmath.exp(2j*np.pi*(H*n + K*m))\n",
    "    return abs(tmp)**2\n",
    "\n",
    "laue(N=32, H=0, K=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "To build an image of the diffraction peak, the continuous Miller indices are sampled in the neighborhood of **H**, **K**:\n",
    "\n",
    "- $h \\in [H-0.5,H+0.5]$\n",
    "- $k \\in [K-0.5,K+0.5]$\n",
    "\n",
    "With $oversampling * N$ samples on each direction, where:\n",
    "\n",
    "- **N** is the number of unit cells of the crystal in both directions\n",
    "- **oversampling** defines how many points are needed to describe a single Laue fringe (2 = Nyquist frequency)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "<img src=\"square_crystal_coordinates.png\" alt=\"Square crystal coordinates\" width=\"300\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "![bragg peak](square_crystal_bragg_peak.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "%matplotlib inline \n",
    "# This is for plotting\n",
    "import math\n",
    "import cmath\n",
    "import numpy as np\n",
    "from matplotlib.pyplot import subplots\n",
    "from matplotlib.colors import LogNorm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "# Miller index of reflection\n",
    "H = 0 \n",
    "# Miller index of reflection\n",
    "K = 4 \n",
    "# Number of unit cells per direction\n",
    "N = 32 \n",
    "# Defines how many points are needed to describe a single Laue fringe (2 = Nyquist frequency)\n",
    "oversampling = 3\n",
    "\n",
    "# Generate real (n,m) and reciprocal (h, k) space coordinates\n",
    "# Generate real and reciprocal space coordinates\n",
    "n = np.arange(N)\n",
    "m = np.arange(N)\n",
    "h = np.arange(H-0.5, H+0.5, 1./(oversampling*N))\n",
    "k = np.arange(K-0.5, K+0.5, 1./(oversampling*N))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "def laue_python(N, h, k):\n",
    "    result = np.zeros((h.size, k.size))\n",
    "    for i_h, v_h in enumerate(h):  # loop over the reciprocal space coordinates\n",
    "        for i_k, v_k in enumerate(k):\n",
    "            tmp = 0.0\n",
    "            for n in range(N):  # loop and sum over unit-cells\n",
    "                for m in range(N):\n",
    "                    tmp += cmath.exp(2j*np.pi*(v_h*n + v_k*m))\n",
    "            result[i_h, i_k] = abs(tmp)**2\n",
    "    return result\n",
    "\n",
    "#Compute\n",
    "%time square_intensity = laue_python(N, h, k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "# Visualization of the reference images\n",
    "fig, ax = subplots(1,2, figsize=(10,5))\n",
    "fig.suptitle(\"Bragg peak\")\n",
    "ax[0].imshow(np.load(\"reference_sq.npy\").T, extent=(h.min(), h.max(), k.min(), k.max()), norm=LogNorm(), origin = 'lower')\n",
    "ax[0].set_xlabel('H')\n",
    "ax[0].set_ylabel('K')\n",
    "ax[0].set_title(f\"Square crystal {N}x{N}\")\n",
    "ax[1].imshow(np.load(\"reference_ci.npy\").T, extent=(h.min(), h.max(), k.min(), k.max()), norm=LogNorm(), origin = 'lower')\n",
    "ax[1].set_xlabel('H')\n",
    "ax[1].set_ylabel('K')\n",
    "ax[1].set_title(f\"Circular crystal {N}x{N}\")\n",
    "pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Validation of optimization\n",
    "\n",
    "Code optimization should always be performed with some tests to ensure the speed-up obtained is not degrading the numerical quality !"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "def validate_sq(result):\n",
    "    \"Return the error value\"\n",
    "    reference = np.load(\"reference_sq.npy\")\n",
    "    return abs(reference-result).max()/reference.max()\n",
    "\n",
    "def validate_ci(result):\n",
    "    \"Return the error value (for exercises)\"\n",
    "    reference = np.load(\"reference_ci.npy\")\n",
    "    return abs(np.array(reference)-result).max()/reference.max()\n",
    "\n",
    "def display(result):\n",
    "    \"Display the array\"\n",
    "    fig, ax = subplots()\n",
    "    fig.suptitle(\"Bragg peak\")\n",
    "    ax.imshow(result.T, extent=(h.min(), h.max(), k.min(), k.max()), norm=LogNorm(), origin = 'lower')\n",
    "    ax.set_xlabel('H');ax.set_ylabel('K')\n",
    "    ax.set_title(f\"Crystal {N}x{N}\")\n",
    "    \n",
    "print(\"Error measured:\", validate_sq(square_intensity))  # Validation of the result:\n",
    "perf_sq_python = %timeit -o laue_python(N, h, k)         # Measure performances of the Python implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "# Run a function in the Python profiler ...\n",
    "%prun -D square.log laue_python(N, h, k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "# Line profiler:\n",
    "%load_ext line_profiler\n",
    "%lprun -f laue_python laue_python(N, h, k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "#Memory profiler\n",
    "%load_ext memory_profiler\n",
    "%memit laue_python(N, h, k)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Exercise\n",
    "\n",
    "\n",
    "### Circular crystal\n",
    "\n",
    "Let's first consider the case of a **circular** crystal rather than a square:\n",
    "1. Write a function generating the diffraction from a **circular** 2D crystal without strain.\n",
    "The previous formula then becomes:\n",
    "   $$ I(H,K) = \\left | \\sum_{n=0}^{N-1} \\sum_{m=0}^{N-1} \\Omega \\left (n,m \\right ) \\exp \\left [ 2 \\pi i \\left ( H n + K m \\right ) \\right ] \\right | ^2$$\n",
    "\n",
    "   With $R=N/2$ the radius of the disk, the support function $\\Omega\\left (n,m \\right )$ is defined as: \n",
    "     * $ \\Omega \\left (n,m \\right ) = 0$  where $(n-N/2)^2+(m-N/2)^2>(N/2)^2$\n",
    "     * $ \\Omega \\left (n,m \\right ) = 1$  where $(n-N/2)^2+(m-N/2)^2 \\leq (N/2)^2$\n",
    "\n",
    "2. How do these modifications affect the result? the execution speed?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "<img src=\"circular_crystal_coordinates.png\" alt=\"Circular crystal coordinates\" width=\"400\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Strained circular crystal\n",
    "\n",
    "Let's consider the case where the circular crystal atoms are not perfectly ordered (**strain**).\n",
    "\n",
    "**Strain** implies that unit-cells are shifted from their regular position according to $\\overrightarrow{r'_i} = \\overrightarrow{r_i} + \\overrightarrow{\\Delta r_i}$, where $\\overrightarrow{\\Delta r_i}$ is the displacement for the cell *i*.\n",
    "For the case of a circular crystal, a function describing a progressive dilatation when moving from the center towards the periphery. \n",
    "It can be written:\n",
    "\n",
    "$$\n",
    "\\overrightarrow{\\Delta r}(\\overrightarrow{r}) = e_{0} \\overrightarrow{r} \\left(1 + \\tanh\\left(\\frac{r-R}{w}\\right)\\right)\n",
    "$$\n",
    "where:\n",
    "\n",
    "- $\\overrightarrow{\\Delta r}(\\overrightarrow{r})$ is the displacement of the unit-cell located at a distance $r$ from the crystal center,\n",
    "- $R=N/2$ is the radius of the disk,\n",
    "- $e_0$ is the maximum strain,\n",
    "- $w$ is a parameter describing the width of the displacement profile (for small values of $w$ the strain is confined at the periphery of the crystal, whereas large values also affect the interior of the crystal)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "![Circular crystal strain map](circular_crystal_strain_map.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "The previous formula then becomes:\n",
    "\n",
    "$$ I(H,K) = \\left | \\sum_{n=0}^{N-1} \\sum_{m=0}^{N-1} \\Omega \\left (n,m \\right ) \\exp \\left \\{ 2 \\pi i \\left [ H \\left (n + \\Delta n_{n,m}\\right )+ K \\left (m + \\Delta m_{n,m}\\right ) \\right ] \\right \\} \\right | ^2$$\n",
    "\n",
    "Where\n",
    "$$\n",
    "\\Delta n_{n,m} = e_0 (n - N/2) \\left(\n",
    "    1 + \\tanh\\left(\n",
    "        \\dfrac{r(n, m) - N/2}{w}\n",
    "    \\right)\n",
    "\\right)\n",
    "$$\n",
    "  \n",
    "$$\n",
    "r(n, m) = \\sqrt{(n - N/2)^2 + (m - N/2)^2}\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "**Exercise**:\n",
    "\n",
    "1. Modify the function to take into account the displacement induced by the strain.\n",
    "2. How these changes affect the result? the execution speed? Store the timimg in `perf_ci_python`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "# Some constants valid for all calculations\n",
    "# Miller index of reflection\n",
    "H = 0 \n",
    "# Miller index of reflection\n",
    "K = 4 \n",
    "# Number of unit cells per direction\n",
    "N = 32 \n",
    "# Defines how many points are needed to describe a single Laue fringe (2 = Nyquist frequency)\n",
    "oversampling = 3\n",
    "\n",
    "# Radius of the crystal\n",
    "R = N/2\n",
    "\n",
    "# Maximum strain at surface\n",
    "e0 = 0.01 \n",
    "# Width of the strain profile below the surface\n",
    "w = 5.\n",
    "\n",
    "# Generate real and reciprocal space coordinates\n",
    "n = np.arange(N)\n",
    "m = np.arange(N)\n",
    "h = np.arange(H-0.5, H+0.5, 1./(oversampling*N))\n",
    "k = np.arange(K-0.5, K+0.5, 1./(oversampling*N))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "# Displacement of atoms as function of the radius\n",
    "def delta(radius, crystal_radius, strain_width):\n",
    "    \"\"\"Displacement of atoms as function of the radius\"\"\"\n",
    "    return 1 + np.tanh((radius - crystal_radius) / strain_width)\n",
    "\n",
    "fig, ax = subplots()\n",
    "x = np.linspace(0, R, 1000)\n",
    "ax.plot(x, delta(x, R, w))\n",
    "ax.set_xlabel(\"Radius\")\n",
    "ax.set_ylabel(\"Displacement\")\n",
    "t = ax.set_title(\"Strain as function of radius\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "1. Implement the circular crystal **without** strain."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "from solution import circ_python_1   # Replace with your implementation\n",
    "# def circ_python_1(N, h, k):\n",
    "#    ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "%time intensity_circle = circ_python_1(N, h, k)\n",
    "print(\"Error:\", validate_ci(intensity_circle))\n",
    "display(intensity_circle)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "2. Extend your code to add strain."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "from solution import circ_python   # Replace with your implementation\n",
    "# def circ_python(N, h, k):\n",
    "#    ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "%time intensity = circ_python(N, h, k)\n",
    "display(intensity)\n",
    "perf_ci_python = %timeit -o circ_python(N, h, k)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "3. Profile your strained crystal diffraction with `%prun` and `%lprun` and `%memit`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "%prun -D circle.log circ_python(N, h, k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "%lprun -f circ_python circ_python(N, h, k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "%memit circ_python(N, h, k)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Optimization with `NumPy`\n",
    "\n",
    "Python is a dynamic language and is known to be pretty inefficient when looping over large datasets.\n",
    "The `numpy` library offers vectorial notation which avoids those loops.\n",
    "\n",
    "### Square crystal implemented with `NumPy`\n",
    "\n",
    "This is how this code looks like once fully vectorized with `NumPy`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def laue_numpy(N, h, k):\n",
    "    h = h.reshape(-1, 1, 1, 1)\n",
    "    k = k.reshape(1, -1, 1, 1)\n",
    "    n = np.arange(N).reshape(1, 1, -1, 1)\n",
    "    m = np.arange(N).reshape(1, 1, 1, -1)\n",
    "    return np.abs(np.sum(np.exp(2j * np.pi * (h*n + k*m)), axis=(2, 3)))**2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "def laue_numpy(N, h, k):\n",
    "    h = h.reshape(-1, 1, 1, 1)\n",
    "    k = k.reshape(1, -1, 1, 1)\n",
    "    n = np.arange(N).reshape(1, 1, -1, 1)\n",
    "    m = np.arange(N).reshape(1, 1, 1, -1)\n",
    "    return np.abs(np.sum(np.exp(2j * np.pi * (h*n + k*m)), axis=(2, 3)))**2\n",
    "\n",
    "# Compute and check error\n",
    "%time intensity = laue_numpy(N, h, k)\n",
    "print(\"Error:\", validate_sq(intensity))\n",
    "perf_sq_numpy = %timeit -o laue_numpy(N, h, k)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "The first striking observation is that the code is much more concise: it can fit in a single line.\n",
    "It is also much clearer: shorter and with a syntax similar to the provided formula.\n",
    "\n",
    "Lines 2-5 add new (empty) dimensions to the input arrays. With this transformation, the calculation of `h*n + k*m` actually returns a 4-dimensional array. This important feature of NumPy is known as [**broadcasting**](https://numpy.org/doc/stable/reference/ufuncs.html#broadcasting).\n",
    "The exponential then operates on all cells of this array.\n",
    "The sum over the real-space coordinates is performed using numpy's `sum()` function: the `axis=(2, 3)` argument tells that the summation has to be performed over the last two dimensions of the array that contain the real space variables.\n",
    "Besides the cleaner syntax, this implementation is also much faster than Python code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "# Broadcasting example\n",
    "a = np.array([1, 2, 3])\n",
    "b = a.reshape(-1, 1)\n",
    "print('a =', a)\n",
    "print('b =', b)\n",
    "print('a*b =', a*b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Exercise\n",
    "\n",
    "1. Implement the strained crystal diffraction using `NumPy` ([Documentation](https://numpy.org/doc/stable/reference/index.html)).\n",
    "2. Profile the code and store the timings in `perf_ci_numpy`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "from solution import circ_numpy   # Replace with your implementation\n",
    "# def circ_numpy(N, h, k):\n",
    "#    ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "#Compute and check error\n",
    "%time intensity = circ_numpy(N, h, k)\n",
    "print(\"Error:\", validate_ci(intensity))\n",
    "perf_ci_numpy = %timeit -o circ_numpy(N, h, k)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Limits of `numpy`'s vectorization\n",
    "\n",
    "When calculating expression like `a+2*b+5*c+a*b`, each individual operation creates a new temporary array where all results of each binary operation are stored. This can be an issue when the number of operands is large and that those temporary arrays are larger than the cache of the processor. Those temporary arrays need to go back to central memory before starting next operation and this is bad for performances."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "#Importance of the cache:\n",
    "def tmp_numpy(N, h, k):\n",
    "    h = h.reshape(-1, 1, 1, 1)\n",
    "    k = k.reshape(1, -1, 1, 1)\n",
    "    n = np.arange(N).reshape(1, 1, -1, 1)\n",
    "    m = np.arange(N).reshape(1, 1, 1, -1)\n",
    "    return np.exp(2j*np.pi*(h*n + k*m))\n",
    "print(f\"Size of the intermediate array: {tmp_numpy(N,h,k).nbytes/2**20:.2f} MiB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "%memit laue_numpy(N, h, k)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Multi-threading in Python\n",
    "\n",
    "Threads are lightweight processes which have all access to the process memory and have some own local memory space. \n",
    "It looks like a good idea to have different threads performing some work in parallel to use the multi-cores of our modern processors. \n",
    "\n",
    "Python offers access to threads via the `threading` library, and offers some convenient tools like the `ThreadPool` from `multiprocessing.pool`, to apply the same function to a set of different inputs. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from multiprocessing.pool import ThreadPool\n",
    "from itertools import product\n",
    "\n",
    "def laue_mt(N, h, k):\n",
    "    n = np.arange(N).reshape(-1, 1)\n",
    "    m = np.arange(N).reshape(1, -1)\n",
    "    def laue_st(hi, ki):\n",
    "        return np.abs(np.exp(2j*np.pi*(hi*n + ki*m)).sum())**2\n",
    "    with ThreadPool(n_cpu) as pool:\n",
    "        tmp = pool.starmap(laue_st, product(h, k))\n",
    "    return np.array(tmp).reshape(h.size, k.size)\n",
    "\n",
    "%time intensity = laue_mt(N, h, k)\n",
    "print(\"Error:\", validate_sq(intensity))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "def laue_mt(N, h, k):\n",
    "    n = np.arange(N).reshape(-1, 1)\n",
    "    m = np.arange(N).reshape(1, -1)\n",
    "    def laue_st(hi, ki):\n",
    "        return np.abs(np.exp(2j*np.pi*(hi*n + ki*m)).sum())**2\n",
    "    with ThreadPool(n_cpu) as pool:\n",
    "        tmp = pool.starmap(laue_st, product(h, k))\n",
    "    return np.array(tmp).reshape(h.size, k.size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "perf_sq_mt = %timeit -o laue_mt(N, h, k)\n",
    "print(f\"Speed-up {perf_sq_numpy.best/perf_sq_mt.best:6.3f}x over {n_cpu} processes\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "By running `htop` during the execution of the previous cell, one validates that many cores are used simultaneously but the execution time is much longer. The performances are ~50% worse than without threads!\n",
    "All threads are **fighting for the Global Interpreter Lock (GIL)**, i.e., they are all waiting for the GIL to be allowed to run a bit of code.\n",
    "This explains why, by going parallel, it is slower (with pure Python code)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Introduction to the GIL\n",
    "\n",
    "Indeed, using threads looks like a good idea but turns out to be more complicated than expected.\n",
    "Having multiple threads accessing to the same Python object, possibly modifying them inplace, is dangerous. \n",
    "This is why developers of Python introduced the GIL (Global Intepreter Lock) which prevents multiple Python objects from being accessed simulaneously.\n",
    "\n",
    "The GIL is at the core of C-Python but other implementations of Python do not suffer from the GIL: PyPy, Jython or IronPython are some examples. \n",
    "For now, there is no reason to hope this will change in the future. Just learn to live with the GIL!\n",
    "\n",
    "There are two ways to work around the GIL:\n",
    "1. Using separated processes\n",
    "2. Use GIL-free sections"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "#### 1. Using separated processes\n",
    "   Processes have distinct memory spaces and can run simultaneously without interfering. There is a `ProcessPool` \n",
    "   which works like the `ThreadPool` except that workers are separated processes. \n",
    "   The drawback of this method is that both the program, operands and the result should be sent to the worker and back.\n",
    "   This requires them to be **serialized** and fully self-consistent. For example the shared variables *n* and *m* are no more allowed. \n",
    "\n",
    "The next cell presents an example of implementation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "from multiprocessing.pool import Pool\n",
    "from itertools import product\n",
    "\n",
    "class LaueSP:\n",
    "    def __init__(self, N):\n",
    "        self.n = np.arange(N).reshape(1, -1)\n",
    "        self.m = np.arange(N).reshape(-1, 1)\n",
    "    def __call__(self, h, k):\n",
    "        return np.abs(np.exp(2j*np.pi*(h*self.n + k*self.m)).sum())**2\n",
    "\n",
    "def laue_mp(N, h, k):\n",
    "    with Pool(n_cpu) as pool:\n",
    "        laue = LaueSP(N)\n",
    "        tmp = pool.starmap(laue, product(h, k))     \n",
    "    return np.array(tmp).reshape(h.size, k.size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "class LaueSP:\n",
    "    def __init__(self, N):\n",
    "        self.n = np.arange(N).reshape(1, -1)\n",
    "        self.m = np.arange(N).reshape(-1, 1)\n",
    "    def __call__(self, h, k):\n",
    "        return np.abs(np.exp(2j*np.pi*(h*self.n + k*self.m)).sum())**2\n",
    "\n",
    "def laue_mp(N, h, k):\n",
    "    with Pool(n_cpu) as pool:\n",
    "        laue = LaueSP(N)\n",
    "        tmp = pool.starmap(laue, product(h, k))     \n",
    "    return np.array(tmp).reshape(h.size, k.size)\n",
    "%time intensity = laue_mp(N, h, k)\n",
    "print(\"Error:\", validate_sq(intensity)) #Compute and check error\n",
    "perf_sq_mt = %timeit -o laue_mp(N, h, k)\n",
    "print(f\"Speed-up {perf_sq_numpy.best/perf_sq_mt.best:6.3f}x over {n_cpu} processes\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "A class instance *laue* has to be used to ship the shared variable ($n$, $m$) to other processes, making the code a bit harder to read for people not used to object oriented programming (OOP).\n",
    "\n",
    "Moreover, the speed-up obtained (2) is far from the resources consumed (4), this is due to the communication overhead."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "#### 2. Use threads with section which are all **GIL-free**\n",
    "\n",
    "   Next section will present three tools which are all compilers able to produce parallel code which is actually run using all cores of your computer.\n",
    "   * `NumExpr`: Fast numerical expression evaluator\n",
    "   * `Numba`: JIT Python compiler\n",
    "   * `Cython`: C-extensions for Python\n",
    "   \n",
    "Several other tools exists (`Pythran`, `Transonic`, ...) but won't be presented."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "# Reload necessary packages, magics, functions and variables\n",
    "%matplotlib inline \n",
    "%load_ext memory_profiler\n",
    "%load_ext line_profiler\n",
    "\n",
    "import os\n",
    "import math\n",
    "import cmath\n",
    "import numpy as np\n",
    "from matplotlib.pyplot import subplots\n",
    "from matplotlib.colors import LogNorm\n",
    "\n",
    "# Number of cores to use\n",
    "if hasattr(os, 'sched_getaffinity'):  # Some Unix only\n",
    "    # Get the number of cores the Python process has access to\n",
    "    # This provides the number of cores requested in SLURM\n",
    "    n_cpu = len(os.sched_getaffinity(0))\n",
    "else:\n",
    "    n_cpu = os.cpu_count()\n",
    "n_cpu = min(8, n_cpu)\n",
    "\n",
    "\n",
    "# Validation functions\n",
    "\n",
    "def validate_sq(result):\n",
    "    \"Return the error value\"\n",
    "    reference = np.load(\"reference_sq.npy\")\n",
    "    return abs(reference-result).max()/reference.max()\n",
    "\n",
    "def validate_ci(result):\n",
    "    \"Return the error value (for exercises)\"\n",
    "    reference = np.load(\"reference_ci.npy\")\n",
    "    return abs(np.array(reference)-result).max()/reference.max()\n",
    "\n",
    "def display(result):\n",
    "    \"Display the array\"\n",
    "    fig, ax = subplots()\n",
    "    fig.suptitle(\"Bragg peak\")\n",
    "    ax.imshow(result.T, extent=(h.min(), h.max(), k.min(), k.max()), norm=LogNorm(), origin = 'lower')\n",
    "    ax.set_xlabel('H');ax.set_ylabel('K')\n",
    "    ax.set_title(f\"Crystal {N}x{N}\")\n",
    "\n",
    "    \n",
    "# Constants\n",
    "# Miller index of reflection\n",
    "H = 0 \n",
    "# Miller index of reflection\n",
    "K = 4 \n",
    "# Number of unit cells per direction\n",
    "N = 32 \n",
    "# Defines how many points are needed to describe a single Laue fringe (2 = Nyquist frequency)\n",
    "oversampling = 3\n",
    "\n",
    "# Radius of the crystal\n",
    "R = N/2\n",
    "\n",
    "# Maximum strain at surface\n",
    "e0 = 0.01 \n",
    "# Width of the strain profile below the surface\n",
    "w = 5.\n",
    "\n",
    "# Generate real and reciprocal space coordinates\n",
    "n = np.arange(N)\n",
    "m = np.arange(N)\n",
    "h = np.arange(H-0.5, H+0.5, 1./(oversampling*N))\n",
    "k = np.arange(K-0.5, K+0.5, 1./(oversampling*N))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## `NumExpr` is a fast numerical expression evaluator for `NumPy`.\n",
    "\n",
    "It works best for evaluating large numerical expressions on arrays which do not fit into cache. The speed-up is typically of the order of 4-8x (may be limited by the number of cores since `numexpr` uses all cores)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "import numexpr as ne\n",
    "ne.set_num_threads(n_cpu)  # Limit the number of threads to be used\n",
    "\n",
    "a = np.arange(10)\n",
    "ne.evaluate(\"sin(a)**2 + cos(a)**2\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "How does `NumExpr` work:\n",
    "1. Parse the mathematical expression \n",
    "2. Compile it in its virtual machine\n",
    "2. Split data into chunks (4096 bytes: cache friendly). Broadcasting is handled as well.\n",
    "3. Chunks can be processed in multiple threads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "# How does NumExpr actually work ...\n",
    "nex = ne.NumExpr(\"sin(a)**2 + cos(a)**2\")\n",
    "print(ne.disassemble(nex))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Square crystal implemented with `NumExpr`\n",
    "\n",
    "* Only the complex exponential part is implemented in `NumExpr`.\n",
    "* `NumExpr` implements efficiently the broadcast of data.\n",
    "* Reductions (sum) exists but it is not faster than `NumPy`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "def laue_numexpr(N, h, k):\n",
    "    h = h.reshape(-1, 1, 1, 1)\n",
    "    k = k.reshape(1, -1, 1, 1)\n",
    "    n = np.arange(N).reshape(1, 1, -1, 1)\n",
    "    m = np.arange(N).reshape(1, 1, 1, -1)\n",
    "    j2pi = np.pi*2j\n",
    "    tmp = ne.evaluate(\"exp(j2pi*(h*n + k*m))\")\n",
    "    return np.abs(np.sum(tmp, axis=(2, 3)))**2\n",
    "\n",
    "#Compute and check error\n",
    "%time intensity = laue_numexpr(N, h, k)\n",
    "print(\"Error:\", validate_sq(intensity))\n",
    "perf_sq_numexpr = %timeit -o laue_numexpr(N, h, k)\n",
    "%memit laue_numexpr(N, h, k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "# Full NumExpr version ... not faster.\n",
    "def laue_numexpr2(N, h, k):\n",
    "    h = h.reshape(-1, 1, 1, 1)\n",
    "    k = k.reshape(1, -1, 1, 1)\n",
    "    n = np.arange(N).reshape(1, 1, -1, 1)\n",
    "    m = np.arange(N).reshape(1, 1, 1, -1)\n",
    "    j2pi = np.pi*2j\n",
    "    tmp = ne.evaluate(\"exp(j2pi*(h*n + k*m))\")\n",
    "    tmp.shape = h.size, k.size, -1\n",
    "    return abs(ne.evaluate(\"sum(tmp, axis=2)\"))**2\n",
    "\n",
    "#Compute and check error\n",
    "intensity = laue_numexpr2(N, h, k)\n",
    "print(\"Error:\", validate_sq(intensity))\n",
    "perf_sq_numexpr2 = %timeit -o laue_numexpr2(N, h, k)\n",
    "%memit laue_numexpr2(N, h, k)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Exercise\n",
    "\n",
    "1. Implement the strained crystal diffraction using `NumExpr` ([User Guide](https://numexpr.readthedocs.io/projects/NumExpr3/en/latest/user_guide.html)).\n",
    "2. Profile the code and store the timings in `perf_ci_numexpr`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "from solution import circ_numexpr   # Replace with your implementation\n",
    "# def circ_numexpr(N, h, k):\n",
    "#    ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "%time  intensity = circ_numexpr(N, h, k)\n",
    "print(\"Error:\", validate_ci(intensity))\n",
    "perf_ci_numexpr = %timeit -o circ_numexpr(N, h, k)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Limits of `NumExpr`\n",
    "* Limited to mathematical functions\n",
    "* Limited to element-wise evaluation (reduction is under development)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## `Numba`, a high performance Python compiler\n",
    "`Numba` is an open source, **Just In Time** compiler that translates a subset of `Python` and `NumPy` code into fast machine code using the `LLVM` compiler library.\n",
    "\n",
    "`Numba` provides a `jit` decorator to indicate the function should be compiled. It usually performs better on explicit loops but accepts most of the `NumPy` constructions. The `jit` decorator takes those options:\n",
    "* signature of the function\n",
    "* `nogil=True`: the function should not contain any Python construct after compilation\n",
    "* `nopython=True`: raises an exception when Python construct remains\n",
    "* `parallel=True`: enables parallel excution with `numba.prange` instead of `range`. Requires `nogil` and `nopython`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"NUMBA_NUM_THREADS\"] = str(n_cpu)  # Limit the number of cores to be used\n",
    "\n",
    "import numba as nb\n",
    "# On recent version on numba: nb.set_num_threads(n_cpu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "@nb.jit\n",
    "def test_one(a):\n",
    "    result = np.zeros(a.shape)\n",
    "    for i in range(a.size):\n",
    "        result[i] = np.cos(a[i])**2 + np.sin(a[i])**2\n",
    "    return result\n",
    "\n",
    "a = np.arange(10)\n",
    "%time test_one(a)\n",
    "%timeit test_one(a)\n",
    "test_one(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "# Get the assembly code\n",
    "for key, value in test_one.inspect_asm().items():\n",
    "    print(\"Signature:\", key)\n",
    "    print(\"Machine code:\\n\",value)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Square crystal implemented with `Numba`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@nb.jit(parallel=True)\n",
    "def laue_numba(N, h, k):\n",
    "    result = np.zeros((h.size, k.size), dtype=np.float64)\n",
    "    for i in nb.prange(h.size):  # loop over the reciprocal space coordinates\n",
    "        for j in range(k.size):\n",
    "            tmp = 0j\n",
    "            for n in range(N):  # loop and sum over unit-cells\n",
    "                for m in range(N):\n",
    "                    tmp +=  cmath.exp(2j*np.pi*(h[i]*n + k[j]*m))\n",
    "            result[i, j] = abs(tmp)**2\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Compute and check error\n",
    "%time intensity = laue_numba(N, h, k)\n",
    "print(\"Error:\", validate_sq(intensity))\n",
    "perf_sq_numba = %timeit -o laue_numba(N, h, k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "%memit laue_numba(N, h, k)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Exercise\n",
    "\n",
    "1. Implement the strained crystal diffraction using `Numba` ([Documentation](https://numba.readthedocs.io/)).\n",
    "2. Profile the code and store the timings in `perf_ci_numba`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "from solution import circ_numba   # Replace with your implementation\n",
    "# @nb.jit(parallel=True)\n",
    "# def circ_numba(N, h, k):\n",
    "#     ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "%time intensity = circ_numba(N, h, k)\n",
    "print(\"Error:\", validate_ci(intensity))\n",
    "perf_ci_numba = %timeit -o  circ_numba(N, h, k)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Limits of `Numba`\n",
    "`Numba` being a JIT compiler, it requires the compiler `LLVM-lite` to be installed and configured on every single node.\n",
    "\n",
    "The second drawback is the JIT: the compilation will be performed for the first execution of a session and if it runs on a cluster, the compilation will occur on every node. Numba is not `multi-processing` friendly.\n",
    "\n",
    "Finally the support for multi-threading in classes looks brittle, at least when evaluated."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Cython: C-extensions for Python\n",
    "\n",
    "Static, ahead-of-time compiler for Python: compiles Python code into C-extensions (or C++ if you wish).\n",
    "\n",
    "Normal Python code gets usually 30% speed-up but for numerical kernels, native C-speed is achievable easily.\n",
    "To get substential speed-up, one need to declare most variables and explicitly write loops. \n",
    "\n",
    "The methodology is pretty similar to `numba`:\n",
    "1. Write the code with loops\n",
    "2. Use the `cython -a` to annotate the code to highlight potential hot-spots, in yellow.\n",
    "3. Declare variables which are not infered with `cdef` and the proper type\n",
    "4. Isolate the numerical kernel and replace numpy functions with the ones provided by the `libc` or `libm` which are guaranteed to be GIL-free."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.environ[\"OMP_NUM_THREADS\"] = str(n_cpu)\n",
    "# This enables the %cython mode\n",
    "%load_ext Cython"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Square crystal implemented with `Cython`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "%%cython --compile-args=-fopenmp --link-args=-fopenmp -a\n",
    "#cython: embedsignature=True, language_level=3, binding=True\n",
    "#cython: boundscheck=False, wraparound=False, cdivision=True, initializedcheck=False,\n",
    "## This is for development:\n",
    "## cython: profile=True, warn.undeclared=True, warn.unused=True, warn.unused_result=False, warn.unused_arg=True\n",
    "\n",
    "import numpy as np\n",
    "from cython.parallel import prange\n",
    "\n",
    "# With Cython3: from libc.complex cimport cabs, cexp\n",
    "# Accessing C code from cython (out of the scope for today)\n",
    "cdef extern from \"complex.h\" nogil:\n",
    "    double cabs(double complex)\n",
    "    double complex cexp(double complex)\n",
    "\n",
    "\n",
    "def laue_cython(int N, \n",
    "                double[::1] h, \n",
    "                double[::1] k):\n",
    "    cdef:\n",
    "        double[:, ::1] result\n",
    "        double complex tmp, two_j_pi\n",
    "        int i_h, i_k, m, n, h_size, k_size\n",
    "        \n",
    "    two_j_pi = np.pi*2j\n",
    "    h_size = h.shape[0]\n",
    "    k_size = k.shape[0]\n",
    "    result = np.zeros((h_size, k_size))\n",
    "    \n",
    "    for i_h in prange(h_size, nogil=True):  # loop over the reciprocal space coordinates\n",
    "        for i_k in range(k_size):\n",
    "            tmp = 0.0\n",
    "            for n in range(N):  # loop and sum over unit-cells\n",
    "                for m in range(N):\n",
    "                    tmp += cexp(two_j_pi*(h[i_h]*n + k[i_k]*m))\n",
    "            result[i_h, i_k] += cabs(tmp)**2\n",
    "    return np.asarray(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "#Compute and check error\n",
    "%time intensity = laue_cython(N, h, k)\n",
    "print(\"Error:\", validate_sq(intensity))\n",
    "perf_sq_cython = %timeit -o laue_cython(N, h, k)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Exercise\n",
    "\n",
    "1. Implement the strained crystal diffraction using `Cython` ([Documentation](http://docs.cython.org/en/latest/)).\n",
    "\n",
    "2. Profile the code and store the timings in `perf_ci_cython`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "%%cython --compile-args=-fopenmp --link-args=-fopenmp -a\n",
    "#%%cython -a\n",
    "#cython: embedsignature=True, language_level=3, binding=True\n",
    "#cython: boundscheck=False, wraparound=False, cdivision=True, initializedcheck=False,\n",
    "## This is for development:\n",
    "## cython: profile=True, warn.undeclared=True, warn.unused=True, warn.unused_result=False, warn.unused_arg=True\n",
    "\n",
    "import numpy as np\n",
    "from cython.parallel import prange\n",
    "from libc.math cimport sqrt, pi, tanh\n",
    "\n",
    "# With Cython3: from libc.complex cimport cabs, cexp\n",
    "# Accessing C code from cython (out of the scope for today)\n",
    "cdef extern from \"complex.h\" nogil:\n",
    "    double cabs(double complex)\n",
    "    double complex cexp(double complex)\n",
    "    \n",
    "def circ_cython(int N, \n",
    "                double[::1] h, \n",
    "                double[::1] k,\n",
    "                double e0,\n",
    "                double w):\n",
    "    return np.ones((h.size, k.size))  # Replace with your implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "#Compute and check error\n",
    "%time intensity = circ_cython(N, h, k, e0, w)\n",
    "print(\"Error:\", validate_ci(intensity))\n",
    "perf_ci_cython = %timeit -o circ_cython(N, h, k, e0, w)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Limits of `Cython`\n",
    "\n",
    "* The learning curve of `Cython` is steeper than the one of `numba` since it targets C/C++ as intermediate language.\n",
    "* Distribution of compiled extensions can be an issue. \n",
    "* Distribution of source code (C or C++) requires the user to install a compiler (rarely on consumer targeted operating systems like Windows & MacOS).\n",
    "* Compiler features depend a lot on the operating system: for instance MacOS removed the support for OpenMP.\n",
    "* Issues about software distribution are addressed in the software engineering training course.\n",
    "\n",
    "The issue about OpenMP not being supported in some environments can be worked around using a `ThreadPool` in Python and a `nogil` section in Cython:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "%%cython -a\n",
    "#cython: embedsignature=True, language_level=3, binding=True\n",
    "#cython: boundscheck=False, wraparound=False, cdivision=True, initializedcheck=False,\n",
    "## This is for development:\n",
    "## cython: profile=True, warn.undeclared=True, warn.unused=True, warn.unused_result=False, warn.unused_arg=True\n",
    "\n",
    "from libc.math cimport pi\n",
    "\n",
    "# With Cython3: from libc.complex cimport cabs, cexp\n",
    "# Accessing C code from cython (out of the scope for today)\n",
    "cdef extern from \"complex.h\" nogil:\n",
    "    double cabs(double complex)\n",
    "    double complex cexp(double complex)\n",
    "\n",
    "    \n",
    "def laue_nogil(int N, \n",
    "               double h, \n",
    "               double k):\n",
    "    cdef:\n",
    "        double result\n",
    "        double complex tmp, two_j_pi\n",
    "        int m, n\n",
    "    \n",
    "    with nogil:\n",
    "        two_j_pi = pi*2j    \n",
    "        tmp = 0.0\n",
    "        for n in range(N):  # loop and sum over unit-cells\n",
    "            for m in range(N):\n",
    "                tmp += cexp(two_j_pi*(h*n + k*m))\n",
    "        result = cabs(tmp)**2\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "from multiprocessing.pool import ThreadPool\n",
    "from itertools import product\n",
    "\n",
    "def laue_pool(N, h, k):\n",
    "    def local_laue(i, j):\n",
    "        return laue_nogil(N, i, j)\n",
    "    with ThreadPool(n_cpu) as pool:\n",
    "        res = pool.starmap(local_laue, product(h, k))\n",
    "    return np.array(res).reshape(h.size, k.size)\n",
    "\n",
    "#Compute and check error\n",
    "%time intensity = laue_pool(N, h, k)\n",
    "print(\"Error:\", validate_sq(intensity))\n",
    "perf_sq_pool = %timeit -o laue_pool(N, h, k) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Other players in the game of optimizing Python code\n",
    "\n",
    "This tutorial demonstrated 4 ways of optimizing:\n",
    "* Vectorization with `NumPy`\n",
    "* Numerical kernel evaluation with `NumExpr`\n",
    "* Just In Time (JIT)-compilation with `Numba`\n",
    "* Ahead Of Time (AOT)-compilation with `Cython`\n",
    "\n",
    "There are several other ways to optimize code:\n",
    "* `Pythran` which is a Python to C++ compiler (with parallel and SIMD vectorization)\n",
    "* `Transonic` which is a wrapper over the different methods exposed here\n",
    "* Write Fortran code and bind it with `F2py`\n",
    "* Write C++ code and bind it with Cython, Boost, pybind11, ...\n",
    "* Write C code and bind it with Cython, ctypes, swig, ...\n",
    "\n",
    "Last but not least, the best way to optimize the code is to use the proper algorithm. \n",
    "In this example, the diffraction of the square crystal can be calculated using a FFT."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Use the right algorithm\n",
    "The best way to optimize the code is to use the proper algorithm. In this example, the diffraction of the square crystal can be calculated using a FFT:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "def laue_fft(N, h, k):\n",
    "    support = np.zeros([h.size,k.size]) #create a support function padded with 0s\n",
    "    support[0:N, 0:N]=1 #the first N values\n",
    "    return np.fft.fftshift(abs(np.fft.fft2(support))**2)\n",
    "\n",
    "%time intensity = laue_fft(N, h, k)\n",
    "print(\"Error:\", validate_sq(intensity))\n",
    "perf_sq_fft = %timeit -o laue_fft(N, h, k)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Unfortunately, the `FFT` approach does not work for strained crystals."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Warning about parallel programming\n",
    "\n",
    "This tutorial presented you several tools for doing parallel processing. Keep in mind parallel processing is **complicated** and many pitfalls exist. We have focused on `Map`, also called `Element-wise` numerical kernel which are well addressed by the `prange` approach. Beside this, risks are great that if you calculate the index position in the loop that you end up with conflicting writes (and incorrect results).\n",
    "\n",
    "## [Amdahl's law](https://en.wikipedia.org/wiki/Amdahl%27s_law)\n",
    "Profile your full application and search for bottlenecks. If you numerical kernel is acounting for 80% of the time, a complete parallelization of it will lead to a speed-up of a factor five, at best.  You have been warned!\n",
    "\n",
    "![Amdahl's Law](https://upload.wikimedia.org/wikipedia/commons/e/ea/AmdahlsLaw.svg)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Conclusions\n",
    "\n",
    "Within the Python ecosystem, the `NumPy` library is the *de facto* standard when it comes to scientific\n",
    "computing. As long as algorithms are properly vectorized and memory is large enough to store\n",
    "arrays, it allows to reach high computational performances while keeping a clean and simple code,\n",
    "close to mathematical notation. Used in combination with `NumExpr` library, simple `NumPy` code\n",
    "can benefit from multi-core CPUs as well as optimized memory management, with very little code\n",
    "modification.\n",
    "\n",
    "In the case where it is not possible to vectorize algorithms, or when increased performances are\n",
    "critical, one must make use of compilers that translate Python code into statically-typed code that also\n",
    "provide an improved support of multi-core architectures. We have shown that `Numba` and `Cython` in\n",
    "general exhibit very close performances and, given the heavier syntax of `Cython`, `Numba` is easier to\n",
    "implement. `Cython`, on the other hand, allows to access more advanced options regarding threads, \n",
    "memory management and debugging."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Summary of the execution runtimes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "print(\"Runtime   Square (ms)  Speed-up (x)\")\n",
    "ref = perf_sq_numpy.best\n",
    "print(f\"Python    {1000*perf_sq_python.best:6.1f} ms   {ref/perf_sq_python.best:6.3f}x\")\n",
    "print(f\"Numpy     {1000*perf_sq_numpy.best:6.1f} ms   {ref/perf_sq_numpy.best:6.3f}x\")\n",
    "print(f\"NumExpr   {1000*perf_sq_numexpr.best:6.1f} ms   {ref/perf_sq_numexpr.best:6.3f}x\")\n",
    "print(f\"Numba     {1000*perf_sq_numba.best:6.1f} ms   {ref/perf_sq_numba.best:6.3f}x\")\n",
    "print(f\"Cython    {1000*perf_sq_cython.best:6.1f} ms   {ref/perf_sq_cython.best:6.3f}x\")\n",
    "print(f\"Pool      {1000*perf_sq_pool.best:6.1f} ms   {ref/perf_sq_pool.best:6.3f}x\")\n",
    "print(f\"FFT       {1000*perf_sq_fft.best:6.1f} ms   {ref/perf_sq_fft.best:6.1f}x\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "print(\"Runtime    Circle (ms)  Speed-up (x)\")\n",
    "ref = perf_ci_numpy.best\n",
    "print(f\"Python  {1000*perf_ci_python.best:8.1f} ms  {ref/perf_ci_python.best:6.3f}x\")\n",
    "print(f\"Numpy   {1000*perf_ci_numpy.best:8.1f} ms  {ref/perf_ci_numpy.best:6.3f}x\")\n",
    "print(f\"NumExpr {1000*perf_ci_numexpr.best:8.1f} ms  {ref/perf_ci_numexpr.best:6.3f}x\")\n",
    "print(f\"Numba   {1000*perf_ci_numba.best:8.1f} ms  {ref/perf_ci_numba.best:6.3f}x\")\n",
    "print(f\"Cython  {1000*perf_ci_cython.best:8.1f} ms  {ref/perf_ci_cython.best:6.3f}x\")\n",
    "# print(f\"Pool    {1000*perf_sq_pool.best:8.1f} ms  {np.NaN:6.3f}x\")"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": ""
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
