{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# HDF5 & python\n",
    "\n",
    "![hdf_group](img/HDF_logo.png \"HDF group\")\n",
    "\n",
    "## what is hdf5 ?\n",
    "\n",
    "[HDF5](https://en.wikipedia.org/wiki/Hierarchical_Data_Format) (for Hierarchical Data Format) is a file format to structure and store data for high volume and complex data\n",
    "\n",
    "## Why hdf5 ?\n",
    "\n",
    "* Hierarchical collection of data (directory and file, UNIX-like path)\n",
    "* Portable file format (Standard exchange format for heterogeneous data)\n",
    "* Rich metadata, self-describing extensible types\n",
    "* Support data compression\n",
    "* Free ( & open source)\n",
    "* Adopted by a large number of institute (NASA, LIGO, ...)\n",
    "* Adopted by most of the synchrotrons (esrf, SOLEIL, Daisy...)\n",
    "* Insure [forward and backward compatibility](https://support.hdfgroup.org/HDF5/doc/ADGuide/CompatFormat180.html)\n",
    "\n",
    "**Data can be mostly anything: image, table, graphs, documents**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## HDF5 description\n",
    "\n",
    "The container is mostly structured with:\n",
    "\n",
    "* **File**: the root of the container\n",
    "* **Group**: a grouping structure containing groups or datasets\n",
    "* **Dataset**: a multidimensional array of data elements\n",
    "* And other features (links, attributes, datatypes)\n",
    "\n",
    "![hdf5_class_diag](img/hdf5_model.png \"hdf5 class diagram\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "\n",
    "## HDF5 example\n",
    "\n",
    "Here is an example of the file generated by [pyFAI](https://github.com/silx-kit/pyFAI)\n",
    "\n",
    "![hdf5_example](img/hdf5_example.png \"hdf5 example\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Usefull tools for HDF5\n",
    "\n",
    "* h5ls, h5dump, hdfview (applications)\n",
    "\n",
    "```bash\n",
    ">>> h5ls -r my_first_one.h5 \n",
    ">>> /                        Group\n",
    ">>> /data1                   Dataset {100, 100}\n",
    ">>> /group1                  Group\n",
    ">>> /group1/data2            Dataset {100, 100}\n",
    "```\n",
    "\n",
    "\n",
    "* silx view (application)\n",
    "\n",
    "```bash\n",
    ">>> pip install silx\n",
    ">>> silx view my_file.h5\n",
    "```\n",
    "\n",
    "* h5glance (HDF5 files in the terminal or an HTML interface)\n",
    "\n",
    "```python\n",
    "from h5glance import H5Glance\n",
    "H5Glance(\"data/ID16B_diatomee.h5\")\n",
    "```\n",
    "\n",
    "==> The HDF group provides a web page with more tools https://support.hdfgroup.org/HDF5/doc/RM/Tools.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## h5py\n",
    "\n",
    "![h5py book](img/h5py.gif \"h5py book\")\n",
    "\n",
    "[h5py](https://www.h5py.org/) is the python binding for accessing hdf5. Originally from [Andrew Collette](http://shop.oreilly.com/product/0636920030249.do)\n",
    "\n",
    "Easy to associate hdf5 and python, everything is represented as a dictionnary."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How to read an hdf5 file with h5py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "first open a file using a [File Object](http://docs.h5py.org/en/stable/high/file.html)\n",
    "```\n",
    "h5py.File('myfile.hdf5', opening_mode)\n",
    "```\n",
    "\n",
    "[opening modes](http://docs.h5py.org/en/stable/high/file.html#opening-creating-files) are:\n",
    "\n",
    "|         |                                                                        |\n",
    "|---------|------------------------------------------------------------------------|\n",
    "| r       | Readonly, file must exist                                              |\n",
    "| r+      | Read/write, file must exist                                            |\n",
    "| w       | Create file, truncate if exists                                        |\n",
    "| w- or x | Create file, fail if exists                                            |\n",
    "| a       | Read/write if exists, create otherwise (default in 'old' h5py version) |\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "import h5py\n",
    "\n",
    "h5file = h5py.File('data/test.h5', 'r')\n",
    "\n",
    "# print available names at the first level\n",
    "print(\"First children:\", list(h5file.keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "# reaching a dataset from a sub group\n",
    "dataset = h5file['diff_map_0004/data/map']\n",
    "dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "datasets mimics numpy-array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# using size and types to not read the full stored data\n",
    "print(\"Dataset: shape:\", dataset.shape, 'size:', dataset.size, 'data type', dataset.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "# read and apply the operation\n",
    "print(type(dataset))\n",
    "print(dataset[5, 5, 0:5])\n",
    "print(2 * dataset[0, 5, 0:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "# copy the data and store it as a numpy-array\n",
    "b = dataset[()]   # ellipsis ('[...]') work also but skip some interpretation\n",
    "print(type(b))\n",
    "b[0, 0, 0:5] = 0\n",
    "print(dataset[0, 0, 0:5])\n",
    "print(b[0, 0, 0:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## How to write an hdf5 with h5py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "import numpy\n",
    "import h5py\n",
    "\n",
    "data = numpy.random.random(10000)\n",
    "data.shape = 100, 100\n",
    "\n",
    "# write\n",
    "h5file = h5py.File('my_first_one.h5', mode='w')\n",
    "\n",
    "# write data into a dataset from the root\n",
    "h5file['/data1'] = data\n",
    "\n",
    "# write data into a dataset from group1\n",
    "h5file['/group1/data2'] = data\n",
    "\n",
    "h5file.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The same operation with a context manager (with statement automatically open and close the file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with h5py.File('my_first_one.h5', mode='w') as h5file:\n",
    "    # write data into a dataset from the root\n",
    "    h5file['/data1'] = data\n",
    "    # write data into a dataset from group1\n",
    "    h5file['/group1/data2'] = data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "More links to:\n",
    "\n",
    "* see [group functions](http://docs.h5py.org/en/stable/high/group.html) for more information like:\n",
    "    * [creating a group](http://docs.h5py.org/en/stable/high/group.html#creating-groups)\n",
    "    * [require a group](http://docs.h5py.org/en/stable/high/group.html#Group.require_group)\n",
    "\n",
    "* see [dataset functions and features](http://docs.h5py.org/en/stable/high/dataset.html) for more information like\n",
    "    * [creating dataset](http://docs.h5py.org/en/stable/high/dataset.html#creating-datasets)\n",
    "\n",
    "* see [h5py documentation regarding attributes](http://docs.h5py.org/en/stable/high/attr.html)\n",
    "\n",
    "* see [hdf5 official documentation](https://portal.hdfgroup.org/display/HDF5) for:\n",
    "    * [chunks](https://portal.hdfgroup.org/display/HDF5/Chunking+in+HDF5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercises"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`data/ID16B_diatomee.h5` structure is like: "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![ID16B diatomee](img/ID16B_diatomee_screenshot.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Exercise 1\n",
    "\n",
    "1. Browse the file ``data/ID16B_diatomee.h5`` (using one or several of the hdf5 utilitaries, silx view, h5glance or h5py)\n",
    "2. Reach a single raw data, a flat field and a dark image (background) from this file\n",
    "3. Apply the flat field correction ${\\frac{rawdata - dark}{flat - dark}}$\n",
    "4. Save the result into a new HDF5 file\n",
    "\n",
    "If you are stuck, the solution is provided in the file [solutions/h5py/exercise1.py](solutions/h5py/exercise1.py)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from h5glance import H5Glance\n",
    "H5Glance(\"data/ID16B_diatomee.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import h5py\n",
    "\n",
    "# Read the data\n",
    "\n",
    "raw =\n",
    "flat = \n",
    "dark = \n",
    "...\n",
    "\n",
    "# Compute the result\n",
    "normalized = \n",
    "\n",
    "# Save the result\n",
    "\n",
    "...\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "note: if you like to plot an image you can use the imshow command\n",
    "!!! the `%pylab` should be called once before calling the imshow function !!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pylab inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy\n",
    "imshow(numpy.random.random((20, 60)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Exercise 2\n",
    "\n",
    "1. Apply the flat field correction to all raw data available (use the same flat and dark for all the images)\n",
    "2. Save each result into different datasets of the same HDF5 file\n",
    "\n",
    "If you are stuck, the solution is provided in the file [solutions/h5py/exercise2.py](solutions/h5py/exercise2.py)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For this you can use the `normalize` function\n",
    "warning: dark and slice are 2d array, data is 3d\n",
    "\n",
    "```python\n",
    "data = normalize(raw_data, dark, flat)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize(data, dark, flat):\n",
    "    assert dark.shape == flat.shape\n",
    "    assert data.shape == dark.shape\n",
    "    return (data - dark) / (flat - dark)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Exercise 3\n",
    "\n",
    "From the previous exercise, we can see that the flat field correction was not very good for the last images.\n",
    "\n",
    "Another flat field was acquired at the end of the acquisition.\n",
    "\n",
    "We could use this information to compute a flat field closer to the image we want to normalize. It can be done with a linear interpolation of the flat images by using the name of the image as the interpolation factor (which varies between 0 and 500 in this case).\n",
    "\n",
    "1. For each raw data, compute the corresponding flat field using lineal interpolation (between `flatfield/0000` and `flatfield/0500`)\n",
    "2. Save each result into different datasets in a single HDF5 file\n",
    "\n",
    "If you are stuck, the solution is provided in the file [solutions/h5py/exercise3.py](solutions/h5py/exercise3.py)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Nexus"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Nexus](https://www.nexusformat.org/) is a data format for neutron, x-ray, and muon science.\n",
    "\n",
    "It aims to be a common data format for scientists for greater collaboration.\n",
    "\n",
    "If you intend to store some data to be shared it can give you a 'standard way' for storing it.\n",
    "\n",
    "The main advantage is to insure compatibility between your data files and existing softwares (if they respect the nexus format) or from your software to different dataset.\n",
    "\n",
    "* an example on [how to store tomography raw data](http://download.nexusformat.org/doc/html/classes/applications/NXtomo.html?highlight=tomography)\n",
    "* an example to store [tomoraphy application (3D reconstruction)](http://download.nexusformat.org/doc/html/classes/applications/NXtomoproc.html?highlight=tomography)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
