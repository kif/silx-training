{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# HDF5\n",
    "\n",
    "![hdf_group](img/HDF_logo.png \"HDF group\")\n",
    "\n",
    "## what is hdf5 ?\n",
    "\n",
    "[HDF5](https://en.wikipedia.org/wiki/Hierarchical_Data_Format) (for Hierarchical Data Format) is a file format to structure and store data for high volume and complex data\n",
    "\n",
    "## Why hdf5 ?\n",
    "\n",
    "* Hierarchical collection of data (directory and file, UNIX-like path)\n",
    "* High-performance (binary)\n",
    "* Portable file format (Standard exchange format for heterogeneous data)\n",
    "* Self-describing extensible types, rich metadata\n",
    "* Support data compression\n",
    "* Free ( & open source)\n",
    "* Adopted by a large number of institute (NASA, LIGO, ...)\n",
    "* Adopted by most of the synchrotrons (esrf, SOLEIL, Daisy...)\n",
    "* Insure [forward and backward compatibility](https://support.hdfgroup.org/HDF5/doc/ADGuide/CompatFormat180.html)\n",
    "\n",
    "**Data can be mostly anything: image, table, graphs, documents**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## HDF5 description\n",
    "\n",
    "The container is mostly structured with:\n",
    "\n",
    "* **File**: the root of the container\n",
    "* **Group**: a grouping structure containing groups or datasets\n",
    "* **Dataset**: a multidimensional array of data elements\n",
    "* And other features (links, attributes, datatypes)\n",
    "\n",
    "![hdf5_class_diag](img/hdf5_model.png \"hdf5 class diagram\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "\n",
    "## HDF5 example\n",
    "\n",
    "Here is an example of the file generated by [pyFAI](https://github.com/silx-kit/pyFAI)\n",
    "\n",
    "![hdf5_example](img/hdf5_example.png \"hdf5 example\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Usefull tools for HDF5\n",
    "\n",
    "* h5ls, h5dump, hdfview\n",
    "```bash\n",
    ">>> h5ls -r my_first_one.h5 \n",
    ">>> /                        Group\n",
    ">>> /data1                   Dataset {100, 100}\n",
    ">>> /group1                  Group\n",
    ">>> /group1/data2            Dataset {100, 100}\n",
    "```\n",
    "\n",
    "* silx view\n",
    "\n",
    "```bash\n",
    ">>> pip install silx\n",
    ">>> silx view my_file.h5\n",
    "```\n",
    "\n",
    "==> The HDF group provides a web page with more tools https://support.hdfgroup.org/HDF5/doc/RM/Tools.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## h5py\n",
    "\n",
    "![h5py book](img/h5py.gif \"h5py book\")\n",
    "\n",
    "[h5py](https://www.h5py.org/) is the python binding for accessing hdf5. Originally from [Andrew Collette](http://shop.oreilly.com/product/0636920030249.do)\n",
    "\n",
    "With time work more and more closely with the hdfgroup.\n",
    "\n",
    "Easy to associate hdf5 and python, everything is represented as a dictionnary."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How to read an hdf5 file with h5py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "first open a file using a [File Object](http://docs.h5py.org/en/stable/high/file.html)\n",
    "```\n",
    "h5py.File('myfile.hdf5', opening_mode)\n",
    "```\n",
    "\n",
    "[opening modes](http://docs.h5py.org/en/stable/high/file.html#opening-creating-files) are:\n",
    "\n",
    "|         |                                                  |\n",
    "|---------|--------------------------------------------------|\n",
    "| r       | Readonly, file must exist                        |\n",
    "| r+      | Read/write, file must exist                      |\n",
    "| w       | Create file, truncate if exists                  |\n",
    "| w- or x | Create file, fail if exists                      |\n",
    "| a       | Read/write if exists, create otherwise (default) |\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "import h5py\n",
    "\n",
    "h5file = h5py.File('data/test.h5', 'r')\n",
    "\n",
    "# print available names at the first level\n",
    "print(\"First children:\", list(h5file['/'].keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "# reaching a dataset from a sub group\n",
    "dataset = h5file['/diff_map_0004/data/map']\n",
    "\n",
    "# using size and types to not read the full stored data\n",
    "print(\"Dataset:\", dataset.shape, dataset.size, dataset.dtype)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "datasets mimics numpy-array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "# read and apply the operation\n",
    "print(dataset[5, 5, 0:5])\n",
    "print(2 * dataset[0, 5, 0:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "# copy the data and store it as a numpy-array\n",
    "b = dataset[...]\n",
    "b[0, 0, 0:5] = 0\n",
    "print(dataset[0, 0, 0:5])\n",
    "print(b[0, 0, 0:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![warning](img/warning.jpg)\n",
    "\n",
    "### Multiple indexing\n",
    "\n",
    "Indexing a dataset once loads a numpy array into memory.\n",
    "If you try to index it twice to write data, you may be surprised that nothing\n",
    "seems to have happened:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = h5py.File('data/my_hdf5_file.h5', 'w')\n",
    "dset = f.create_dataset(\"test\", (2, 2))\n",
    "dset[0][1] = 3.0  # No effect!\n",
    "# This assignment only modifies the loaded array. It's equivalent to this:\n",
    "print('orginal value:', dset[0][1])\n",
    "\n",
    "new_array = dset[0]\n",
    "new_array[1] = 3.0\n",
    "print('value modified (in the copy):', new_array[1])\n",
    "print('orginal value:', dset[0][1])\n",
    "\n",
    "# To write to the dataset, combine the indexes in a single step:\n",
    "dset[0, 1] = 3.0\n",
    "print(dset[0, 1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## How to write an hdf5 with h5py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "import numpy\n",
    "import h5py\n",
    "\n",
    "data = numpy.arange(10000.0)\n",
    "data.shape = 100, 100\n",
    "\n",
    "# write\n",
    "h5file = h5py.File('my_first_one.h5', mode='w')\n",
    "\n",
    "# write data into a dataset from the root\n",
    "h5file['/data1'] = data\n",
    "\n",
    "# write data into a dataset from group1\n",
    "h5file['/group1/data2'] = data\n",
    "\n",
    "h5file.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## display contains of an hdf5 file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## writing a .h5 file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## reading a .h5 file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hand on - normalization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### step 1: load data, dark and flat from file/data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import h5py\n",
    "with h5py.File(myfile.h5) as h5:\n",
    "    data = ...\n",
    "    dark = ... \n",
    "    flat = ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### step 2: apply normalization for each slice of the data\n",
    "\n",
    "For this you can use the `normalize` function\n",
    "warning: dark and slice are 2d array, data is 3d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize(data, dark, flat):\n",
    "    assert dark.shape == flat.shape\n",
    "    assert data.shape == dark.shape\n",
    "    return (data - dark) / (flat - dark)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### step 3: store the normalize data into a new dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hands on 2\n",
    "\n",
    "those are the grades of different student during the semesters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy\n",
    "\n",
    "def grade():\n",
    "    return numpy.random.randint(low=0, high=20)\n",
    "    \n",
    "exam_1_result = {'Adriana': grade(), 'Helene': grade(), 'Mohamed': grade(), 'Lian': grade(), 'Martin': grade(), 'Moussa': grade()}\n",
    "exam_2_result = {'Adriana': grade(), 'Helene': grade(), 'Mohamed': grade(), 'Lian': grade(), 'Martin': grade(), 'Moussa': grade()}\n",
    "exam_3_result = {'Adriana': grade(), 'Helene': grade(), 'Mohamed': grade(), 'Lian': grade(), 'Martin': grade(), 'Moussa': grade()}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "step1: Store all those results in a all_result.h5 file with the following dataset:\n",
    "- 'exam 1 result': contains the results of the first exam\n",
    "- 'exam 2 result'\n",
    "- 'exam 3 result'\n",
    "- results mean: contains for each student the mean other the three controls. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "step2: **from the all_results.h5** file create one file for each student containing only their grades for each of the exam and the mean of the three exams."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Nexus"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Nexus](https://www.nexusformat.org/) is a data format for neutron, x-ray, and muon science.\n",
    "\n",
    "It defined a common to represente dataset."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
